####### This is the Shell and R script to detect aneuploidy and large CNVs using ####### rapid nanopore short-read sequencing data. 
####### The pipeline can be run at 15-min interval or 
####### after the run data are sufficient for analysis 

############### before you start: 
############### replace the {path to fastq_pass folder}
############### replace the {name of the run} 
############### replace the {path to STORK supple. files}
############### locate {path to GRCh37 Bowtie2 Index} on local computer and on HPC


cd {path to fastq_pass folder} 
pwd 

time gunzip *.fastq.gz
rm {name of the run}.fastq
touch {name of the run}.fastq

############### Use the actual number of fastq files in the folder 
############### Replace 573 with the actual number of fastq files 
############### e.g., {0..100};{101..200}; etc 


time for i in {0..573}; do echo *_$i.fastq; cat *_$i.fastq >> {name of the run}.fastq; done

wc -l {name of the run}.fastq 
 
time for f in {name of the run}.fastq; do echo $f; grep -A1 "read" $f | sed -e 's/^@/>/g' -e '/--/d' > ${f%.fastq}.fasta; done

time gzip *.fastq
cp {path to STORK supple. files}/Vbarcores.top.22.fasta.gz .
gunzip Vbarcores.top.22.fasta.gz


################ Demultiplex samples in a run ##################################

awk '{print substr($0,1,21)};' Vbarcores.top.22.fasta > Vbarcores.top.21.fasta
time cutadapt -g file:Vbarcores.top.21.fasta -O 20 -e 0.2 -m 150 -o {name of the run}.{name}.cut2.21.m150.fasta {name of the run}.fasta >{name of the run}.cut2.21.m150.log

wc -l {name of the run}.V*.cut2.21.m150.fasta
      
time cutadapt -g file:Vbarcores.top.21.fasta -O 20 -e 0.15 -m 150 -o {name of the run}.{name}.cut1.21.m150.fasta {name of the run}.fasta >{name of the run}.cut1.21.m150.log


for f in {name of the run}.V??.cut2.21.m150.fasta; do echo $f; head -220000 $f > ${f%.fasta}.110K.fasta; wc -l ${f%.fasta}.110K.fasta; done

############### remove the demultiplexed files from unused barcodes. 
rm {name of the run}.V13.cut2.21.m150.fasta
rm {name of the run}.V14.cut2.21.m150.fasta
rm {name of the run}.V15.cut2.21.m150.fasta

################  Trim the adaptors and save up to 400bp 
time for f in {name of the run}.V*.cut2.21.m150.110K.fasta ; do echo $f; awk '{if ($1~">") {print $0}}; {if ($1!~">") {print substr($0,50,length($0)-100);}}' $f |  awk '{if ($1~">") {print $0}}; {if ($1!~">"){print substr($0,0,400);}}' > ${f%.fasta}.trim.400bp.fasta; wc -l ${f%.fasta}.trim.400bp.fasta; done

for f in {name of the run}.V??.cut2.21.m150.110K.fasta; do echo $f; samtools faidx $f; cut -f2 $f.fai | Rscript -e 'data <- as.numeric (readLines ("stdin")); summary(data); hist(data, breaks=2000)'; mv Rplots.pdf $f.pdf; done

for f in {name of the run}.V??.cut2.21.m150.110K.fasta; do echo $f; cut -f2 $f.fai | Rscript -e 'data <- as.numeric (readLines ("stdin")); summary(data); hist(data, breaks=2000)'; mv Rplots.pdf $f.pdf; done >{name of the run}.QC.list
 
Echo "Read length summary:"
cat {name of the run}.QC.list
awk '$0~"Min" {getline; print $0;}' {name of the run}.QC.list
     
################ upload the fasta files to HPC cluster ##############
scp {name of the run}.V??.cut2.21.m150.110K.trim.400bp.fasta {path to HPC}

Echo "Data uploaded, please run the blat.sh script on HPC for multi-thread alignment"

################ run the blat.sh script on HPC cluster ###################
ssh {HPC} 

## Submit the blat.sh script based one the actual HPC environment 
## On HPC, submit one sample in one blat.{i}.sh script,
## use multiple cores to analyze up to 12 samples simultaneously
## bash and environment headers not included 
## refer to https://github.com/icebert/pblat-cluster to complete a qsub script,
## and a sbatch script 

################ blat.{}.sh script without header ###########

### here insert the qsub or sbatch script headers ########

cd {path to fastq_pass folder}
#file="{name of the run}.V01.cut2.21.m150.110K.trim.400bp.fasta"
file=$(ls {name of the run}.V??.cut2.21.m150.110K.trim.400bp.fasta)

for f in $file;
do
    echo $f;        
    fn=$(basename $f);
    echo $fn;
                
######### locate {path to the GRCh37 Bowtie2 Index}
######### locate {path to the pblat} and {path to UCSC software}
######### use 96 threads for alignment 

	time {path to the pblat}/pblat -threads=96 -minIdentity=80 -minScore=40 -tileSize=10 -maxIntron=500 {path to the GRCh37 Bowtie2 Index}/genome.fa $f ${f%.fasta}.GRCh37.pblat.psl

	{path to UCSC software}/pslReps -minCover=0.40 -minAli=0.80 -nearTop=0.001 -singleHit ${f%.fasta}.GRCh37.pblat.psl ${f%.fasta}.GRCh37.pblat.pslReps.psl ${f%.fasta}.GRCh37.pblat.pslReps.psr

	wc -l ${f%.fasta}.GRCh37.pblat.pslReps.psl 	
	gzip ${f%.fasta}.GRCh37.pblat.psl
	gzip ${f%.fasta}.GRCh37.pblat.pslReps.psl
              
	gzip $f
		
done

################## end of blat.{}.sh script ##################

########### If performed on HPC cluster, download the *.pslReps.psl.gz files 
########### move the *.pslReps.psl.gz files to a new psl folder for analysis 
########### at local workstation 
mkdir psl
mv {name of the run}.V*.cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.gz psl
cd psl
echo "path to the psl folder"
pwd
############### This is your {path to the psl folder}  ################

############### process the pblat-aligned data 
 
gunzip {name of the run}.V??.cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.gz
 
time for f in {name of the run}.V??.cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl; do echo $f; wc -l $f; cut -f10 $f | sort | uniq -u > $f.uni.ID; awk 'FNR==NR{a[$0];next}($10 in a)' $f.uni.ID $f > $f.uni; wc -l $f.uni; done

############### Count the reads assigned to each chromosome 
############### Summary on 80K reads. If higher coverage are needed, change 
############### 80 to a higher number 


################# 10M analysis with 400bp 80K reads ###################
######## locate {path to STORK supple. files}
######## locate {path to the psl folder}

cd {path to the psl folder}
cp {path to STORK supple. files}/psl2sam.pl .
cp {path to STORK supple. files}/chr.10M.bed .

awk '($0~"MT") || ($0~"X") || ($0~"Y") {print $0}' chr.10M.bed > chr.10M.MT-X-Y.sort.bed
awk '($0!~"MT") && ($0!~"X") && ($0!~"Y") {print $0}' chr.10M.bed | sort -k1n -k2n > chr.10M.auto.sort.bed
cat chr.10M.MT-X-Y.sort.bed chr.10M.auto.sort.bed > chr.10M.sort.bed


time for f in *.110K.trim.400bp.GRCh37.pblat.pslReps.psl; do echo $f; wc -l $f; cut -f10 $f | sort | uniq -u > $f.uni.ID; awk 'FNR==NR{a[$0];next}($10 in a)' $f.uni.ID $f > $f.uni; wc -l $f.uni; done


for f in *.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni; do echo $f; awk '(NR<=80003 && NR>3) {print $0;}' $f > $f.80K; wc -l $f.80K; done

gzip *.GRCh37.pblat.pslReps.psl

############### use samtools v1.2  
############### bedtools 2.28 
############### locate {path to GRCh37 Bowtie2 Index}

time for f in  *.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K; do echo $f; psl2sam.pl $f > $f.sam; samtools view -bT {path to GRCh37 Bowtie2 Index}/genome.fa $f.sam | samtools sort - $f.sorted ; samtools index $f.sorted.bam; bedtools coverage -a chr.10M.sort.bed -b $f.sorted.bam > $f.sorted.10M.sort.bed; rm $f.sam; done

time for f in  *.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K; do echo $f; awk '{print$1":"$2"-"$3"\t"$4;}' $f.sorted.10M.sort.bed >  $f.sorted.10M.sort.bed.forSta; head $f.sorted.10M.sort.bed.forSta; done

mkdir 80K10M
cp *.80K.sorted.10M.sort.bed.forSta 80K10M
cd 80K10M
pwd
cp {path to STORK supple. files}/Axis.10M.txt .


########## Perform the copy number analysis in R or Rstudio v3
########## Firstly, count the number of reads in each 10MB bins using the ########## internal reference sample V12 for normalization


KaryoMaleRef=function(KM,Ki){
 KM$V3=KM[,2]/sum(KM[1:323,2])
 Ki$V3=Ki[,2]/sum(Ki[1:323,2])
 print("########### Normalize to normal male 24, XY ############")
 Ki$V4=Ki[,3]/KM[,3]
 

 ################## 25% for full aneuploidy ##############
 SDautosome=sd(Ki[which(Ki[24:323,4]>0.75 & Ki[24:323,4]<1.25)+23,4])
 Meanautosome=mean(Ki[which(Ki[24:323,4]>0.75 & Ki[24:323,4]<1.25)+23,4])

 ################### 15% for mosaic ######################
 #SDautosome=sd(Ki[which(Ki[24:323,4]>0.85 & Ki[24:323,4]<1.15)+23,4])
 #Meanautosome=mean(Ki[which(Ki[24:323,4]>0.85 & Ki[24:323,4]<1.15)+23,4])

 
 Ki$V5=(Ki[,4]-Meanautosome)/SDautosome
 Ki$V6=((abs(Ki[,5])>=3.29 & KM[,2]>199)|(abs(Ki[,5])>=6 & KM[,2]>50))
 Ki$V7=1-pnorm(abs(Ki[,5]))
 q=qnorm(0.001, mean=Meanautosome, sd=SDautosome)
 Ki$V8=pnorm(q,mean=Ki[,4],sd=SDautosome,lower.tail=FALSE)
 colnames(Ki)=c("Chr","UR","%UR","%UR/%URref","Z-score","Abnormal?","pNormal","pB")
	return(Ki)
 }

########## locate the internal reference sample with barcode V12 

KM=read.table("{name of the run}.V12.cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K.sorted.10M.sort.bed.forSta")
files=list.files(pattern = "\\.(uni.80K.sorted.10M.sort.bed.forSta)$")


K.result=vector("list",length(files))
	names(K.result)=paste(files)
	K=vector("list",length(files))
	names(K)=paste(files)
	for (i in 1:length(files)){
	K[[i]]=read.table(files[[i]])
 }
 
for (i in 1:length(files)){
	K.result[[i]]=KaryoMaleRef(KM,K[[i]])
}

for (i in 1:length(files)){
	print(K.result[i])
 write.csv(K.result[[i]],paste(names(K)[i],".male.V2-V12R.200up.result.csv",sep=""))
 
sampleNames=files

for (i in 1:length(files)){
	sampleNames[i]=sub("uni.80K.sorted.10M.sort.bed.forSta","",files[i])
 }

Axis=read.csv("Axis.10M.txt",sep="\t",header = FALSE)

shortNames=files
for (i in 1:length(files)){
shortNames[i]=sub(".cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K.sorted.10M.sort.bed.forSta","",files[i])
 }
shortNames


for (i in 1:length(files)){
pdf(paste(as.character(shortNames[i]),"noMT","200up","V2-V12R","V6","pdf",sep="."),width=8,height=3,pointsize=10)
col = c("black","red")[factor(K.result[[i]][2:323,6])]
col[which(KM[,2]<50)-1]="gray"

plot(K.result[[i]][2:323,4],ylim=c(0,3),cex=0.5,main=as.character(shortNames[i]),ylab="Relative copy number",pch=20,xlab="chromosome",xaxt='n',col=col)
axis(1,2:323,Axis[2:323,2],las=2)
for (i in 2:323){

if (Axis[i,2]!= "")
abline(v=i-1,lty="dashed",col = "gray60")
}

dev.off()


}


################## Calculate CV of 300 10M bins on autosomes  
################## using a internal reference sample V12 

table=K.result[[1]][,4]
for (i in (2:length(files))){
table=cbind(table,K.result[[i]][,4])
}

row.names(table)=K[[1]][,1]
array=c(sampleNames)
colnames(table)=array

write.table(table,"table.v4.V2-V12R.2.result.list",sep="\t",quote=F)

######## reads v2 ##########
table=K.result[[1]][,2]
for (i in (2:length(files))){
table=cbind(table,K.result[[i]][,2])
}

row.names(table)=K[[1]][,1]
array=c(sampleNames)
colnames(table)=array

write.table(table,"table.v2.V2-V12R.2.result.list",sep="\t",quote=F)


tableCV=c()
for (i in (1:length(files))){
tableCV[i]=sd(K.result[[i]][which(K.result[[i]][24:323,4]!="NaN" &  K.result[[i]][24:323,4]!="Inf")+23,4])/mean(K.result[[i]][which(K.result[[i]][24:323,4]!="NaN" &  K.result[[i]][24:323,4]!="Inf")+23,4])
}

write.table(tableCV,"tableCV.v4.V2-V12R.2.result.list",sep="\t",quote=F)

q()

####### CV of bins can be found in tableCV.v4.V2-V12R.2.result.list

#############################################################################
####### A virtual reference should be build by the lab performing the test for ####### best results  
####### Current virtual reference sample is V.80K.10R.ref.txt
####### Replace the name of the reference sample V.80K.10R.ref.txt

cp {path to STORK supple. files}/V.80K.10R.ref.txt .
R

##########################################################################
###################### in R v3.4 or v3.5  ############################
###################### Using the virtual reference made by the testing lab
###################### Normalize to the virtual reference 


KaryoMaleRef=function(KM,Ki){
 KM$V3=KM[,2]/sum(KM[1:323,2])
 Ki$V3=Ki[,2]/sum(Ki[1:323,2])
 print("########### Normalize to normal male 24, XY ############")
 Ki$V4=Ki[,3]/KM[,2]
  

################### 25% for full aneuploidy ######################
SDautosome=sd(Ki[which(Ki[24:323,4]>0.75 & Ki[24:323,4]<1.25)+23,4])
Meanautosome=mean(Ki[which(Ki[24:323,4]>0.75 & Ki[24:323,4]<1.25)+23,4])

################### 15% for mosaic ######################
#SDautosome=sd(Ki[which(Ki[24:323,4]>0.85 & Ki[24:323,4]<1.15)+23,4])
#Meanautosome=mean(Ki[which(Ki[24:323,4]>0.85 & Ki[24:323,4]<1.15)+23,4])
 
 Ki$V5=(Ki[,4]-Meanautosome)/SDautosome
 Ki$V6=((abs(Ki[,5])>=3.29 & KM[,4]>200)|(abs(Ki[,5])>=4 & KM[,4]>180)|(abs(Ki[,5])>=5 & KM[,4]>140)|(abs(Ki[,5])>=6 & KM[,4]>=70))
 Ki$V7=1-pnorm(abs(Ki[,5]))
 q=qnorm(0.001, mean=Meanautosome, sd=SDautosome)
 Ki$V8=pnorm(q,mean=Ki[,4],sd=SDautosome,lower.tail=FALSE)
 
 Ki$V9=Ki[,4]/Meanautosome
 
 
 SDautosomeAdj=sd(Ki[which(Ki[24:323,9]>0.75 & Ki[24:323,9]<1.25)+23,4])
 MeanautosomeAdj=mean(Ki[which(Ki[24:323,9]>0.75 & Ki[24:323,9]<1.25)+23,4])

 Ki$V10=(Ki[,9]-MeanautosomeAdj)/SDautosomeAdj
 
 Ki$V11=((abs(Ki[,10])>=3.29 & KM[,4]>300)|(abs(Ki[,10])>=4 & KM[,4]>240)|(abs(Ki[,10])>=5 & KM[,4]>200)|(abs(Ki[,10])>=6 & KM[,4]>=80))
 
 colnames(Ki)=c("Chr","UR","%UR","%UR/%URref","Z-score","Abnormal?","pNormal","pB","adj%","AdjZ-score","AdjAbnormal")
 return(Ki)
 }

KM=read.table("V.80K.10R.ref.txt",header=T)
files=list.files(pattern = "\\.(uni.80K.sorted.10M.sort.bed.forSta)$")
files


K.result=vector("list",length(files))
names(K.result)=paste(files)
K=vector("list",length(files))
names(K)=paste(files)
for (i in 1:length(files)){
K[[i]]=read.table(files[[i]])
 }
 
for (i in 1:length(files)){
K.result[[i]]=KaryoMaleRef(KM,K[[i]])
}

for (i in 1:length(files)){
 print(K.result[i])
 write.csv(K.result[[i]],paste(names(K)[i],".male_sum10R.10M.200up.result.csv",sep=""))
}


sampleNames=files
for (i in 1:length(files)){
sampleNames[i]=sub("uni.80K.sorted.10M.sort.bed.forSta","",files[i])
 }

Axis=read.csv("Axis.10M.txt",sep="\t",header = FALSE)


shortNames=files
for (i in 1:length(files)){
shortNames[i]=sub(".cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K.sorted.10M.sort.bed.forSta","",files[i])
 }
shortNames

######## Firstly make a dot plot based on the unadjusted Z-score, noted V6  

for (i in 1:length(files)){
pdf(paste(as.character(shortNames[i]),"noMT","200up","male_10R","V6","pdf",sep="."),width=8,height=3,pointsize=10)
col = c("black","red")[factor(K.result[[i]][2:323,6])]
col[which(KM[,4]<80)-1]="gray"

plot(K.result[[i]][2:323,4],ylim=c(0,3),cex=0.5,main=as.character(shortNames[i]),ylab="Relative copy number",pch=20,xlab="chromosome",xaxt='n',col=col)
axis(1,2:323,Axis[2:323,2],las=2)
for (i in 2:323){

if (Axis[i,2]!= "")
abline(v=i-1,lty="dashed",col = "gray60")
}

dev.off()


}

######## Then make a dot plot based on the adjusted Z-score, noted v11  
for (i in 1:length(files)){
pdf(paste(as.character(shortNames[i]),"noMT","200up","male_10R","V11","pdf",sep="."),width=8,height=3,pointsize=10)
col = c("black","red")[factor(K.result[[i]][2:323,11])]
col[which(KM[,4]<80)-1]="gray"

plot(K.result[[i]][2:323,9],ylim=c(0,3),cex=0.5,main=as.character(shortNames[i]),ylab="Relative copy number",pch=20,xlab="chromosome",xaxt='n',col=col)
axis(1,2:323,Axis[2:323,2],las=2)
for (i in 2:323){

if (Axis[i,2]!= "")
abline(v=i-1,lty="dashed",col = "gray60")
}

dev.off()


}

############### Calculate the CV of 300 10M bins using virtual reference ######

table=K.result[[1]][,4]
for (i in (2:length(files))){
table=cbind(table,K.result[[i]][,4])
}

row.names(table)=K[[1]][,1]
array=c(sampleNames)
colnames(table)=array

write.table(table,"table.v4.male_10R.2.result.list",sep="\t",quote=F)

tableCV=c()
for (i in (1:length(files))){
tableCV[i]=sd(K.result[[i]][which(K.result[[i]][24:323,4]!="NaN" &  K.result[[i]][24:323,4]!="Inf")+23,4])/mean(K.result[[i]][which(K.result[[i]][24:323,4]!="NaN" &  K.result[[i]][24:323,4]!="Inf")+23,4])
}

write.table(tableCV,"tableCV.v4.male_10R.2.result.list",sep="\t",quote=F)
q()
#### tableCV.v4.male_10R.2.result.list is the list of CV of bins of all samples
#### compare this with the CV of 300 10M bins using a internal reference V12 

#########################################################################
############# 10MF2, a 50% window shift of the 10MB bins ##########
############# under the {path to psl folder} 

cd {path to psl folder}
cp {path to STORK supple. files}/psl2sam.pl .
cp {path to STORK supple. files}/chr.10M.F2.bed .
pwd

wc -l chr.10M.F2.bed
 
awk '($0~"MT") || ($0~"X") || ($0~"Y") {print $0}' chr.10M.F2.bed > chr.10M.F2.MT-X-Y.sort.bed
awk '($0!~"MT") && ($0!~"X") && ($0!~"Y") {print $0}' chr.10M.F2.bed | sort -k1n -k2n > chr.10M.F2.auto.sort.bed
cat chr.10M.F2.MT-X-Y.sort.bed chr.10M.F2.auto.sort.bed > chr.10M.F2.sort.bed


for f in *.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni; do echo $f; awk '(NR<=80003 && NR>3) {print $0;}' $f > $f.80K; wc -l $f.80K; done

for f in *.80K; do echo $f; cut -f14 $f | sort -k1,1n | uniq -c > $f.temp; awk '{if (NR==1 && $2 !~ "MT") {print "0","MT"}}; {print $0};' $f.temp > $f.summary; awk '{print "chr"$2"\t"$1;}' $f.summary > $f.summary.forSta; head $f.summary.forSta;done


######### Assume the bam files had been generated from 10M analysis 

time for f in *.400bp.GRCh37.pblat.pslReps.psl.uni.80K; do echo $f; bedtools coverage -a chr.10M.F2.sort.bed -b $f.sorted.bam > $f.sorted.10M.F2.sort.bed; done 

time for f in *.400bp.GRCh37.pblat.pslReps.psl.uni.80K; do echo $f; awk '{print$1":"$2"-"$3"\t"$4;}' $f.sorted.10M.F2.sort.bed > $f.sorted.10M.F2.sort.bed.forSta; head $f.sorted.10M.F2.sort.bed.forSta; done

mkdir 80K10MF2
cp *.uni.80K.sorted.10M.F2.sort.bed.forSta 80K10MF2

######## use the virtual reference file generated by the testing lab #######
cd 80K10MF2
pwd
cp {path to STORK supple. files}/Axis.10MF2.txt .
cp {path to STORK supple. files}/V.80K.F2.10R.ref.txt .

####################### Run in R ############################
R
list.files(pattern = "\\.(uni.80K.sorted.10M.F2.sort.bed.forSta)$")
files=list.files(pattern = "\\.(uni.80K.sorted.10M.F2.sort.bed.forSta)$")
files

#### First calculate coverage in each 10MF2 bin using internal referece V12


KaryoMaleRef=function(KM,Ki){
 KM$V3=KM[,2]/sum(KM[1:336,2])
 Ki$V3=Ki[,2]/sum(Ki[1:336,2])
 print("########### Normalize to normal male 26, XY ############")
 Ki$V4=Ki[,3]/KM[,3]
 
 ############### 25% for full aneuploidy ################ 
 SDautosome=sd(Ki[which(Ki[,4]>0.75),][which(Ki[which(Ki[,4]>0.75),][,4]<1.25),][,4])
 Meanautosome=mean(Ki[which(Ki[,4]>0.75),][which(Ki[which(Ki[,4]>0.75),][,4]<1.25),][,4])

 ############### 15% for mosaic ################ 
#SDautosome=sd(Ki[which(Ki[,4]>0.85),][which(Ki[which(Ki[,4]>0.85),][,4]<1.15),][,4])
#Meanautosome=mean(Ki[which(Ki[,4]>0.85),][which(Ki[which(Ki[,4]>0.85),][,4]<1.15),][,4])

 Ki$V5=(Ki[,4]-Meanautosome)/SDautosome
 Ki$V6=((abs(Ki[,5])>=3.29 & KM[,2]>199)|(abs(Ki[,5])>=6 & KM[,2]>99))
 Ki$V7=1-pnorm(abs(Ki[,5]))
 q=qnorm(0.001, mean=Meanautosome, sd=SDautosome)
 Ki$V8=pnorm(q,mean=Ki[,4],sd=SDautosome,lower.tail=FALSE)
 
 Ki$V9=Ki[,4]/Meanautosome
 
 SDautosomeAdj=sd(Ki[which(Ki[26:336,9]>0.85 & Ki[26:336,9]<1.15)+25,4])
 MeanautosomeAdj=mean(Ki[which(Ki[26:336,9]>0.85 & Ki[26:336,9]<1.15)+25,4])

 Ki$V10=(Ki[,9]-MeanautosomeAdj)/SDautosomeAdj
 
 Ki$V11=((abs(Ki[,10])>=3.29 & KM[,2]>200)|(abs(Ki[,10])>=4 & KM[,2]>180)|(abs(Ki[,10])>=5 & KM[,2]>140)|(abs(Ki[,10])>=6 & KM[,2]>=70))
 
colnames(Ki)=c("Chr","UR","%UR","%UR/%URref","Z-score","Abnormal?","pNormal","pB","adj%","AdjZ-score","AdjAbnormal")
 return(Ki)

 }


KM=read.table("{name of the run}.V12.cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K.sorted.10M.F2.sort.bed.forSta")
files=list.files(pattern = "\\.(uni.80K.sorted.10M.F2.sort.bed.forSta)$")
files


K.result=vector("list",length(files))
names(K.result)=paste(files)
K=vector("list",length(files))
names(K)=paste(files)
for (i in 1:length(files)){
K[[i]]=read.table(files[[i]])
 }
 
 for (i in 1:length(files)){
K.result[[i]]=KaryoMaleRef(KM,K[[i]])
}
for (i in 1:length(files)){
 print(K.result[i])
 write.csv(K.result[[i]],paste(names(K)[i],".male.V2-V12R.200up.result.csv",sep=""))
 
}


sampleNames=files
for (i in 1:length(files)){
sampleNames[i]=sub("uni.80K.sorted.10M.F2.sort.bed.forSta","",files[i])
 }


Axis=read.csv("Axis.10MF2.txt",sep="\t",header = FALSE)


shortNames=files
for (i in 1:length(files)){
shortNames[i]=sub(".cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K.sorted.10M.F2.sort.bed.forSta","",files[i])
 }
 
shortNames


for (i in 1:length(files)){
pdf(paste(as.character(shortNames[i]),"noMT","200up","V2-V12R","V6","pdf",sep="."),width=8,height=3,pointsize=10)
col = c("black","red")[factor(K.result[[i]][2:336,6])]
col[which(KM[,2]<50)-1]="gray"

plot(K.result[[i]][2:336,4],ylim=c(0,3),cex=0.5,main=as.character(shortNames[i]),ylab="Relative copy number",pch=20,xlab="chromosome",xaxt='n',col=col)
axis(1,2:336,Axis[2:336,2],las=2)
for (i in 2:336){

if (Axis[i,2]!= "")
abline(v=i-1,lty="dashed",col = "gray60")
}

dev.off()


}

############## calculate CV of 311 10MF2 bins on autosome ##############

table=K.result[[1]][,4]
for (i in (2:length(files))){
table=cbind(table,K.result[[i]][,4])
}

row.names(table)=K[[1]][,1]
array=c(sampleNames)
colnames(table)=array

write.table(table,"table.v4.V2-V12R.2.result.list",sep="\t",quote=F)

######## reads v2 ##########
table=K.result[[1]][,2]
for (i in (2:length(files))){
table=cbind(table,K.result[[i]][,2])
}

row.names(table)=K[[1]][,1]
array=c(sampleNames)
colnames(table)=array

write.table(table,"table.v2.V2-V12R.2.result.list",sep="\t",quote=F)

tableCV=c()
for (i in (1:length(files))){
tableCV[i]=sd(K.result[[i]][which(K.result[[i]][26:336,4]!="NaN" &  K.result[[i]][26:336,4]!="Inf")+23,4])/mean(K.result[[i]][which(K.result[[i]][26:336,4]!="NaN" &  K.result[[i]][26:336,4]!="Inf")+23,4])
}

tableCV=cbind(shortNames,tableCV)
write.table(tableCV,"tableCV.v4.V2-V12R.2.result.list",sep="\t",quote=F)

############### CV in the tableCV.v4.V2-V12R.2.result.list ##############
##########################################################################
############### Use the virtual reference for normalization 

KaryoMaleRef=function(KM,Ki){
#KM$V3=KM[,2]/sum(KM[1:336,2])
 Ki$V3=Ki[,2]/sum(Ki[1:336,2])
 print("########### Normalize to normal male 24, XY ############")
 Ki$V4=Ki[,3]/KM[,2]
 
######## 25% for full aneuploidy ####################
SDautosome=sd(Ki[which(Ki[26:336,4]>0.75 & Ki[26:336,4]<1.25)+25,4])
Meanautosome=mean(Ki[which(Ki[26:336,4]>0.75 & Ki[26:336,4]<1.25)+25,4])

######## 15% for mosaic ####################
#SDautosome=sd(Ki[which(Ki[26:336,4]>0.85 & Ki[26:336,4]<1.15)+25,4])
#Meanautosome=mean(Ki[which(Ki[26:336,4]>0.85 & Ki[26:336,4]<1.15)+25,4])


 
 Ki$V5=(Ki[,4]-Meanautosome)/SDautosome
 Ki$V6=((abs(Ki[,5])>=3.29 & KM[,4]>200)|(abs(Ki[,5])>=4 & KM[,4]>160)|(abs(Ki[,5])>=5 & KM[,4]>140)|(abs(Ki[,5])>=6 & KM[,4]>=80))
 Ki$V7=1-pnorm(abs(Ki[,5]))
 Ki$V7=1-pnorm(abs(Ki[,5]))
 q=qnorm(0.001, mean=Meanautosome, sd=SDautosome)
 Ki$V8=pnorm(q,mean=Ki[,4],sd=SDautosome,lower.tail=FALSE)
 
 Ki$V9=Ki[,4]/Meanautosome
 
 
 SDautosomeAdj=sd(Ki[which(Ki[26:336,9]>0.75 & Ki[26:336,9]<1.25)+25,4])
 MeanautosomeAdj=mean(Ki[which(Ki[26:336,9]>0.75 & Ki[26:336,9]<1.25)+25,4])

 Ki$V10=(Ki[,9]-MeanautosomeAdj)/SDautosomeAdj
 
 Ki$V11=((abs(Ki[,10])>=3.29 & KM[,4]>200)|(abs(Ki[,10])>=4 & KM[,4]>160)|(abs(Ki[,10])>=5 & KM[,4]>140)|(abs(Ki[,10])>=6 & KM[,4]>=80))
 
  
  ###### with Z-score for each bin, optional  ##########
 
# Ki$V12=(Ki[,2]-KM[,4])/KM[,5]
# Ki$V13=((abs(Ki[,12])>=3.29 & KM[,4]>300)|(abs(Ki[,12])>=4 & KM[,4]>240)|(abs(Ki[,12])>=5 & KM[,4]>200)|(abs(Ki[,12])>=6 & KM[,4]>=80))
#colnames(Ki)=c("Chr","UR","%UR","%UR/%URref","Z-score","Abnormal?","pNormal","pB","adj%","AdjZ-score","AdjAbnormal","Bin-Zscore","Bin-Abnormal")
 
 colnames(Ki)=c("Chr","UR","%UR","%UR/%URref","Z-score","Abnormal?","pNormal","pB","adj%","AdjZ-score","AdjAbnormal")
 return(Ki)
 }


KM=read.table("V.80K.F2.10R.ref.txt",header=T)
files=list.files(pattern = "\\.(uni.80K.sorted.10M.F2.sort.bed.forSta)$")
files

K.result=vector("list",length(files))
names(K.result)=paste(files)
K=vector("list",length(files))
names(K)=paste(files)
for (i in 1:length(files)){
K[[i]]=read.table(files[[i]])
 }
 
for (i in 1:length(files)){
K.result[[i]]=KaryoMaleRef(KM,K[[i]])
}

for (i in 1:length(files)){
 print(K.result[i])
 write.csv(K.result[[i]],paste(names(K)[i],".V_male_sum10R.10M.F2.200up.result.csv",sep=""))
}


sampleNames=files
for (i in 1:length(files)){
sampleNames[i]=sub("uni.80K.sorted.10M.F2.sort.bed.forSta","",files[i])
 }


Axis=read.csv("Axis.10MF2.txt",sep="\t",header = FALSE)


shortNames=files
for (i in 1:length(files)){
shortNames[i]=sub(".cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K.sorted.10M.F2.sort.bed.forSta","",files[i])
 }
 
shortNames
 
########### dotplots factored by unadjusted Z-score, noted with V6 
for (i in 1:length(files)){
pdf(paste(as.character(shortNames[i]),"80K","noMT","200up","V_male_sum10R","V6","pdf",sep="."),width=8,height=3,pointsize=10)
col = c("black","red")[factor(K.result[[i]][2:336,6])]
col[which(KM[,2]<0.0009000)-1]="gray"

plot(K.result[[i]][2:336,4],ylim=c(0,3),cex=0.5,main=as.character(shortNames[i]),ylab="Relative copy number",pch=20,xlab="chromosome",xaxt='n',col=col)
axis(1,2:336,Axis[2:336,2],las=2)
for (i in 2:336){

if (Axis[i,2]!= "")
abline(v=i-1,lty="dashed",col = "gray60")
}

dev.off()

}

########### dotplots factored by unadjusted Z-score, noted with V11 
for (i in 1:length(files)){
pdf(paste(as.character(shortNames[i]),"noMT","200up","V_male_sum10R","V11","pdf",sep="."),width=8,height=3,pointsize=10)
col = c("black","red")[factor(K.result[[i]][2:336,11])]
col[which(KM[,4]<80)-1]="gray"

plot(K.result[[i]][2:336,9],ylim=c(0,3),cex=0.5,main=as.character(shortNames[i]),ylab="Relative copy number",pch=20,xlab="chromosome",xaxt='n',col=col)
axis(1,2:336,Axis[2:336,2],las=2)
for (i in 2:336){

if (Axis[i,2]!= "")
abline(v=i-1,lty="dashed",col = "gray60")
}

dev.off()


}

############ Calculate CV of 311 10MF2 bins on autosomes ############
############ using virtual reference 
###################### CV table ##############################

table=K.result[[1]][,4]
for (i in (2:length(files))){
table=cbind(table,K.result[[i]][,4])
}

row.names(table)=K[[1]][,1]
array=c(sampleNames)
colnames(table)=array

write.table(table,"table.v4.80K.V_male_sum10R.2.result.list",sep="\t",quote=F)

tableCV=c()
for (i in (1:length(files))){
tableCV[i]=sd(K.result[[i]][which(K.result[[i]][26:336,4]!="NaN" &  K.result[[i]][26:336,4]!="Inf")+23,4])/mean(K.result[[i]][which(K.result[[i]][26:336,4]!="NaN" &  K.result[[i]][26:336,4]!="Inf")+23,4])
}
tableCV=cbind(shortNames,tableCV)
write.table(tableCV,"tableCV.v4.80K.V_male_sum10R.2.result.list",sep="\t",quote=F)

q()
cd ..
pwd 
##############################################################################
################ combine the results of 10M & 10MF2 bins ##################### 

cd {path to psl folder}
cp {path to STORK supple. files}/10M2B.location .
pwd

for f in *.cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K; do echo $f; wc -l 80K10M/$f.sorted.10M.sort.bed.forSta.male_sum10R.10M.200up.result.csv; wc -l 80K10MF2/$f.sorted.10M.F2.sort.bed.forSta.male_10R.10M.F2.200up.result.csv; done


##################### combine the the 200up ############
##################### 10R ###################################
for f in *.cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K; do echo $f; rm $f.10M.combined; touch $f.10M.combined; cat 80K10M/$f.sorted.10M.sort.bed.forSta.male_sum10R.10M.200up.result.csv 80K10MF2/$f.sorted.10M.F2.sort.bed.forSta.male_10R.10M.F2.200up.result.csv >> $f.10M.combined; cut -d "," -f 2- $f.10M.combined | sed -e 's/"//g' -e 's/,/       /g' > $f.10M.combined.temp; rm $f.10M.combined; paste 10M2B.location $f.10M.combined.temp | sort -k1,1 -k2,2n -k3,3n > $f.10M.combined.loc;  awk '($0~"MT") || ($0~"X") || ($0~"Y") {print $0}' $f.10M.combined.loc > $f.10M.combined.MT-X-Y.sort; awk '($0!~"MT") && ($0!~"X") && ($0!~"Y") {print $0}' $f.10M.combined.loc | sort -k1n -k2n -k3,3n | awk 'NR>2 {print $0}' > $f.10M.combined.auto.sort; cat $f.10M.combined.MT-X-Y.sort $f.10M.combined.auto.sort > $f.10M.combine.sort.temp; cut -f2 $f.10M.combine.sort.temp | awk '{OFS="\t"} {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13}' > $f.10M.combine.sort; rm $f.10M.combined.MT-X-Y.sort; rm $f.10M.combined.auto.sort; rm $f.10M.combined.temp; rm $f.10M.combine.sort.temp; rm $f.10M.combined.loc; done

mkdir 80K10M2B/10R
cp *.80K.10M.combine.sort 80K10M2B/10R
cd 80K10M2B/10R
pwd

### use the virtual reference for the combined 10M and 10MF2 bins 
### generated by the testing lab
cp {path to STORK supple. files}/10M2B.Axis.txt .
cp {path to STORK supple. files}/V.80K.10M2B.10R.ref.txt .


#############################################################################
R
########################## in R ########################################

KM=read.table("V.80K.10M2B.10R.ref.txt",header=T)
files=list.files(pattern = "\\.(uni.80K.10M.combine.sort)$")
files

KaryoMaleRef=function(KM,Ki){
#KM$V3=KM[,2]/sum(KM[1:659,2])
 Ki$V3=Ki[,2]/sum(Ki[1:659,2])
 print("########### Normalize to normal male 24, XY ############")
 Ki$V4=Ki[,3]/KM[,2]
 
 

SDautosome=sd(Ki[which(Ki[49:659,4]>0.75 & Ki[49:659,4]<1.25)+48,4])
Meanautosome=mean(Ki[which(Ki[49:659,4]>0.75 & Ki[49:659,4]<1.25)+48,4])


 Ki$V5=(Ki[,4]-Meanautosome)/SDautosome
 Ki$V6=((abs(Ki[,5])>=3.29 & KM[,4]>200)|(abs(Ki[,5])>=4 & KM[,4]>160)|(abs(Ki[,5])>=5 & KM[,4]>140)|(abs(Ki[,5])>=6 & KM[,4]>79))
 Ki$V7=1-pnorm(abs(Ki[,5]))
 q=qnorm(0.001, mean=Meanautosome, sd=SDautosome)
 Ki$V8=pnorm(q,mean=Ki[,4],sd=SDautosome,lower.tail=FALSE)
 Ki$V9="NA"
 colnames(Ki)=c("Chr","UR","%UR","%UR/%URref","Z-score","Abnormal?","pNormal","pB")
 return(Ki)
 }


K=vector("list",length(files))
names(K)=paste(files)
for (i in 1:length(files)){
K[[i]]=read.table(files[[i]])
 }


K.result=vector("list",length(files))
names(K.result)=paste(files)
for (i in 1:length(files)){
K.result[[i]]=read.table(files[[i]])
colnames(K.result[[i]])=c("Chr","UR","%UR","%UR/%URref","Z-score","Abnormal?","pNormal","pB")
 }

 
sampleNames=files
for (i in 1:length(files)){
sampleNames[i]=sub("uni.80K.10M.combine.sort","",files[i])
 }
sampleNames

Axis=read.csv("10M2B.Axis.txt",sep="\t",header = FALSE)

shortNames=files
for (i in 1:length(files)){
shortNames[i]=sub(".cut2.21.m150.110K.trim.400bp.GRCh37.pblat.pslReps.psl.uni.80K.10M.combine.sort","",files[i])
 }
 
shortNames

########## dotplots using the unadjusted Z-score, noted by V6
for (i in 1:length(files)){
pdf(paste(as.character(shortNames[i]),"80K","noMT","10M2B","200up","V_male_sum10R","V6","pdf",sep="."),width=8,height=3,pointsize=10)
col = c("black","red")[factor(K.result[[i]][3:659,6])]
col[which(KM[,4]<80)-2]="gray"

plot(K.result[[i]][3:659,4],ylim=c(0,3),cex=0.5,main=as.character(shortNames[i]),ylab="Relative copy number",pch=20,xlab="chromosome",xaxt='n',col=col)
axis(1,3:659,Axis[3:659,2],las=2)
for (i in 3:659){

if (Axis[i,2]!= "")
abline(v=i-1,lty="dashed",col = "gray60")
}

dev.off()


}

########### dotplots using the adjusted Z-score, noted by V11
########### use V11 for aneuploidy calling  
for (i in 1:length(files)){
pdf(paste(as.character(shortNames[i]),"80K","noMT","10M2B","200up","V_male_sum10R","V11","pdf",sep="."),width=8,height=3,pointsize=10)
col = c("black","red")[factor(K.result[[i]][3:659,11])]
col[which(KM[,4]<80)-2]="gray"

plot(K.result[[i]][3:659,9],ylim=c(0,3),cex=0.5,main=as.character(shortNames[i]),ylab="Relative copy number",pch=20,xlab="chromosome",xaxt='n',col=col)
axis(1,3:659,Axis[3:659,2],las=2)
for (i in 3:659){

if (Axis[i,2]!= "")
abline(v=i-1,lty="dashed",col = "gray60")
}

dev.off()


}

########## Calculate the CV of the combined 611 10MB bins from 300 10M and 311 ##########   10MF2 with 50% window shift on autosomes  
###################### CV table ##############################
table=K.result[[1]][,4]
for (i in (2:length(files))){
table=cbind(table,K.result[[i]][,4])
}

row.names(table)=K[[1]][,1]
array=c(sampleNames)
colnames(table)=array

write.table(table,"table.v4.80K.V_male_sum10R.10M2B.comb.result.list",sep="\t",quote=F)

tableCV=c()
for (i in (1:length(files))){
tableCV[i]=sd(K.result[[i]][which(K.result[[i]][49:659,4]!="NaN" &  K.result[[i]][49:659,4]!="Inf")+48,4])/mean(K.result[[i]][which(K.result[[i]][49:659,4]!="NaN" &  K.result[[i]][49:659,4]!="Inf")+48,4])
}
write.table(tableCV,"tableCV.v4.80K.V_male_sum10R.10M2B.comb.result.list",sep="\t",quote=F

######## CV value of read coverage on 300 10M bins and 311 10MF2 bins of each ######## sample in tableCV.v4.80K.V_male_sum10R.10M2B.comb.result.list
######## using a virtual reference 
######## Compare this CV with the CV using an internal reference, 
######## or other references. 

q()
cd ..
pwd

#############################################################################
###### after the analysis, gzip the large files and move to cold storage 


